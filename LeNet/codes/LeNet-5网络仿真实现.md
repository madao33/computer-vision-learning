# LeNet-5ç½‘ç»œä»¿çœŸå®ç°

## LeNet-5ç½‘ç»œæ¶æ„ä»‹ç»

`LeNet-5`ç½‘ç»œæ¶æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸åŒ…æ‹¬è¾“å…¥å±‚çš„è¯ï¼Œ`LeNet-5`ä¸€å…±æœ‰7å±‚ï¼Œæ‰€æœ‰çš„å±‚éƒ½æœ‰å¯ä»¥è®­ç»ƒçš„å‚æ•°(æƒé‡).
![](https://www.madao33.com/media/LeNet-5ç½‘ç»œä»¿çœŸå®ç°/lenet5.png)
è¾“å…¥çš„å›¾åƒæ˜¯  $32\times32$ å°ºå¯¸çš„ç‚¹é˜µå›¾ï¼Œè¿™æ¯”ç”¨äºè®­ç»ƒçš„æ•°æ®åº“ä¸­çš„æœ€å¤§çš„å­—ç¬¦è¿˜è¦å¤§(æ•°æ®åº“ä¸­çš„å¤§å¤šæ•°æ•°æ®å°ºå¯¸åœ¨ $20\times20$â€‹â€‹â€‹â€‹)ã€‚è¿™æ ·åšçš„åŸå› æ˜¯æœŸæœ›è¯†åˆ«åˆ°æ½œåœ¨çš„åŒºåˆ«ç‰¹å¾ï¼Œä¾‹å¦‚ç¬”åˆ’ç»ˆç‚¹æˆ–è½¬è§’å¯ä»¥å‡ºç°åœ¨æœ€é«˜æ°´å¹³ç‰¹å¾æ£€æµ‹å™¨çš„æ„Ÿå—é‡çš„ä¸­å¿ƒã€‚åœ¨ $32\times32$â€‹çš„è¾“å…¥æ•°æ®ä¸­ï¼ŒLeNet-5ç½‘ç»œçš„æœ€åä¸€å±‚å·ç§¯å±‚çš„æ„Ÿå—é‡ä¸­å¿ƒå½¢æˆ $20\times20$â€‹çš„åŒºåŸŸã€‚

è¾“å…¥çš„æ•°æ®ç»è¿‡å½’ä¸€åŒ–ï¼Œç™½è‰²çš„ç‚¹åœ¨-0.1ï¼Œé»‘è‰²çš„ç‚¹åœ¨1.175ï¼Œè¿™æ ·è®©è¾“å…¥çš„å¹³å‡å€¼åœ¨0å·¦å³ï¼Œæ–¹å·®åœ¨1å·¦å³ï¼Œå¯ä»¥åŠ é€Ÿå­¦ä¹ ã€‚


è¿™ä¸ªç½‘ç»œæ¶æ„è™½ç„¶æ¯”è¾ƒå°ï¼Œä½†æ˜¯ä¹ŸåŒ…å«äº†æ·±åº¦å­¦ä¹ çš„ä¸»è¦çš„åŸºæœ¬æ¨¡å—ï¼š

### input layer

æ•°æ®è¾“å…¥å±‚ï¼Œå°†è¾“å…¥å›¾åƒå°ºå¯¸ç»Ÿä¸€å¹¶å½’ä¸€åŒ–ä¸º $32\times32$

### c1å·ç§¯å±‚(convolutional layer)

* è¾“å…¥ï¼š$32 \times 32$

* å·ç§¯æ ¸å¤§å°ï¼š$5\times5, s=1$â€‹

* å·ç§¯ç§ç±»ï¼š6

* ç¥ç»å…ƒæ•°é‡ï¼š$28\times28\times6$

* å¯è®­ç»ƒå‚æ•°ï¼š$(5\times5+1)\times6=156$â€‹ 

  > æ¯ä¸ªæ»¤æ³¢å™¨ $5\times5=25$â€‹ä¸ª`unit`å‚æ•°å’Œä¸€ä¸ª`bias`å‚æ•°ï¼Œä¸€å…±6ä¸ªæ»¤æ³¢å™¨

* è¿æ¥æ•°ï¼š$(5\times5+1)\times6\times28\times28=122304$â€‹

  > å·ç§¯å±‚`C1`å†…çš„æ¯ä¸ªåƒç´ éƒ½ä¸è¾“å…¥å›¾åƒä¸­çš„ $5\times5$â€‹ä¸ªåƒç´ å’Œ1ä¸ªbiasæœ‰è¿æ¥ï¼Œæ‰€ä»¥æ€»å…±æœ‰ $156\times28\times28=12304$â€‹ ä¸ªè¿æ¥ç‚¹

> å¯¹è¾“å…¥å›¾åƒè¿›è¡Œç¬¬ä¸€æ¬¡å·ç§¯è¿ç®—ï¼ˆä½¿ç”¨ 6 ä¸ªå¤§å°ä¸º $5\times5$â€‹â€‹â€‹â€‹ çš„å·ç§¯æ ¸ï¼‰ï¼Œå¾—åˆ°6ä¸ª`C1`ç‰¹å¾å›¾ï¼ˆ6ä¸ªå¤§å°ä¸º$28\times28$â€‹â€‹çš„ `feature maps`, 32-5+1=28ï¼‰ã€‚æˆ‘ä»¬å†æ¥çœ‹çœ‹éœ€è¦å¤šå°‘ä¸ªå‚æ•°ï¼Œå·ç§¯æ ¸çš„å¤§å°ä¸º$5\times5$â€‹â€‹ï¼Œæ€»å…±å°±æœ‰$6\times(5\times5+1)=156$â€‹â€‹â€‹ä¸ªå‚æ•°ï¼Œå…¶ä¸­+1æ˜¯è¡¨ç¤ºä¸€ä¸ªæ ¸æœ‰ä¸€ä¸ª`bias`ã€‚å¯¹äºå·ç§¯å±‚`C1`ï¼Œ`C1`å†…çš„æ¯ä¸ªåƒç´ éƒ½ä¸è¾“å…¥å›¾åƒä¸­çš„$5\times5$â€‹â€‹ä¸ªåƒç´ å’Œ1ä¸ª`bias`æœ‰è¿æ¥ï¼Œæ‰€ä»¥æ€»å…±æœ‰$156\times28\times28=122304$â€‹â€‹â€‹ä¸ªè¿æ¥ï¼ˆconnectionï¼‰ã€‚æœ‰122304ä¸ªè¿æ¥ï¼Œä½†æ˜¯æˆ‘ä»¬åªéœ€è¦å­¦ä¹ 156ä¸ªå‚æ•°ï¼Œä¸»è¦æ˜¯é€šè¿‡æƒå€¼å…±äº«å®ç°çš„ã€‚

### S2æ± åŒ–å±‚(sub-sampS2ling layer)

* è¾“å…¥ï¼š$28\times28$
* é‡‡æ ·åŒºåŸŸï¼š$2\times2$
* é‡‡æ ·æ–¹å¼ï¼š4ä¸ªè¾“å…¥ç›¸åŠ ï¼Œä¹˜ä»¥ä¸€ä¸ªå¯è®­ç»ƒå‚æ•°ï¼Œå†åŠ ä¸Šä¸€ä¸ªå¯è®­ç»ƒåç½®ã€‚ç»“æœé€šè¿‡`sigmoid`å‡½æ•°
* é‡‡æ ·ç§ç±»ï¼š6
* è¾“å‡º`featureMap`å¤§å°ï¼š$14\times14(28/2)$â€‹
* ç¥ç»å…ƒæ•°é‡ï¼š$14\times14\times6$â€‹
* å¯è®­ç»ƒå‚æ•°ï¼š$2\times6$â€‹(å’Œçš„æƒ+åç½®)
* è¿æ¥æ•°ï¼š$(2\times2+1)\times6\times14\times14$â€‹
* `S2`ä¸­æ¯ä¸ªç‰¹å¾å›¾çš„å¤§å°æ˜¯`C1`ä¸­ç‰¹å¾å›¾å¤§å°çš„1/4ã€‚

> ç¬¬ä¸€æ¬¡å·ç§¯ä¹‹åç´§æ¥ç€å°±æ˜¯æ± åŒ–è¿ç®—ï¼Œä½¿ç”¨ $2\times 2$â€‹â€‹â€‹æ ¸è¿›è¡Œæ± åŒ–ï¼Œäºæ˜¯å¾—åˆ°äº†`S2`ï¼Œ6ä¸ª$14\times14$â€‹â€‹â€‹â€‹çš„ç‰¹å¾å›¾ï¼ˆ28/2=14ï¼‰ã€‚`S2`è¿™ä¸ªpoolingå±‚æ˜¯å¯¹C1ä¸­çš„ $2\times2$â€‹â€‹â€‹â€‹ åŒºåŸŸå†…çš„åƒç´ æ±‚å’Œä¹˜ä»¥ä¸€ä¸ªæƒå€¼ç³»æ•°å†åŠ ä¸Šä¸€ä¸ªåç½®ï¼Œç„¶åå°†è¿™ä¸ªç»“æœå†åšä¸€æ¬¡æ˜ å°„ã€‚äºæ˜¯æ¯ä¸ªæ± åŒ–æ ¸æœ‰ä¸¤ä¸ªè®­ç»ƒå‚æ•°ï¼Œæ‰€ä»¥å…±æœ‰2x6=12ä¸ªè®­ç»ƒå‚æ•°ï¼Œä½†æ˜¯æœ‰5x14x14x6=5880ä¸ªè¿æ¥ã€‚

### C3å·ç§¯å±‚(convolutional layer)

* `S2`ä¸­æ‰€æœ‰6ä¸ªæˆ–è€…å‡ ä¸ªç‰¹å¾`map`ç»„åˆ
* å·ç§¯æ ¸å¤§å°ï¼š$5\times5$
* å·ç§¯æ ¸ç§ç±»ï¼š16
* è¾“å‡º`featureMap`å¤§å°ï¼š$10\times10(14-5+1)=10$

![](https://www.madao33.com/media/LeNet-5ç½‘ç»œä»¿çœŸå®ç°/table1.png)

`C3`ä¸­çš„æ¯ä¸ªç‰¹å¾`map`æ˜¯è¿æ¥åˆ°`S2`ä¸­çš„æ‰€æœ‰6ä¸ªæˆ–è€…å‡ ä¸ªç‰¹å¾`map`çš„ï¼Œè¡¨ç¤ºæœ¬å±‚çš„ç‰¹å¾`map`æ˜¯ä¸Šä¸€å±‚æå–åˆ°çš„ç‰¹å¾`map`çš„ä¸åŒç»„åˆã€‚å­˜åœ¨çš„ä¸€ä¸ªæ–¹å¼æ˜¯ï¼š`C3`çš„å‰6ä¸ªç‰¹å¾å›¾ä»¥`S2`ä¸­3ä¸ªç›¸é‚»çš„ç‰¹å¾å›¾å­é›†ä¸ºè¾“å…¥ã€‚æ¥ä¸‹æ¥6ä¸ªç‰¹å¾å›¾ä»¥`S2`ä¸­4ä¸ªç›¸é‚»ç‰¹å¾å›¾å­é›†ä¸ºè¾“å…¥ã€‚ç„¶åçš„3ä¸ªä»¥ä¸ç›¸é‚»çš„4ä¸ªç‰¹å¾å›¾å­é›†ä¸ºè¾“å…¥ã€‚æœ€åä¸€ä¸ªå°†`S2`ä¸­æ‰€æœ‰ç‰¹å¾å›¾ä¸ºè¾“å…¥ã€‚åˆ™ï¼šå¯è®­ç»ƒå‚æ•°ï¼š
$$
6\times(3\times5\times5+1)+6\times(4\times5\times5+1)+3\times(4\times5\times5+1)+\times(6\times5\times5+1)=1516
$$
è¿™ç§éå¯¹ç§°çš„è¿æ¥çš„ä½œç”¨æ˜¯ï¼š

* éå®Œå…¨è¿æ¥çš„æ–¹æ¡ˆå¯ä»¥ä½¿è¿æ¥æ•°ä¿æŒåœ¨åˆç†çš„èŒƒå›´å†…
* ä¸åŒçš„ç‰¹å¾å›¾å› ä¸ºæœ‰ä¸åŒçš„ç‰¹å¾å¯ä»¥æå–å¤šç§ç»„åˆ

### S4æ± åŒ–å±‚(sub-sampling layer)

* è¾“å…¥ï¼š$10\times10$
* é‡‡æ ·åŒºåŸŸï¼š$2\times2$
* é‡‡æ ·æ–¹å¼ï¼š4ä¸ªè¾“å…¥ç›¸åŠ ï¼Œä¹˜ä»¥ä¸€ä¸ªå¯è®­ç»ƒå‚æ•°ï¼Œå†åŠ ä¸Šä¸€ä¸ªå¯è®­ç»ƒåç½®ã€‚ç»“æœé€šè¿‡`sigmoid`
* é‡‡æ ·ç§ç±»ï¼š16
* è¾“å‡º`featureMap`å¤§å°ï¼š$5\times5$
* ç¥ç»å…ƒæ•°é‡ï¼š$5\times5\times16=400$
* å¯è®­ç»ƒå‚æ•°ï¼š$2\times16=32$
* è¿æ¥æ•°ï¼š$16\times(2\times2+1)\times5\times5=2000$â€‹
* `S4`ä¸­æ¯ä¸ªç‰¹å¾å›¾çš„å¤§å°æ˜¯`C3`ä¸­ç‰¹å¾å›¾å¤§å°çš„1/4

> `S4`æ˜¯`pooling`å±‚ï¼Œçª—å£å¤§å°ä»ç„¶æ˜¯$2\times2$â€‹â€‹â€‹ï¼Œå…±è®¡16ä¸ª`feature map`ï¼Œ`C3`å±‚çš„16ä¸ª$10\times10$â€‹â€‹â€‹çš„å›¾åˆ†åˆ«è¿›è¡Œä»¥$2\times2$â€‹â€‹â€‹ä¸ºå•ä½çš„æ± åŒ–å¾—åˆ°16ä¸ª $5\times5$â€‹â€‹â€‹ çš„ç‰¹å¾å›¾ã€‚è¿™ä¸€å±‚æœ‰2x16å…±32ä¸ªè®­ç»ƒå‚æ•°ï¼Œ$5\times5\times5\times16=2000$â€‹â€‹ ä¸ªè¿æ¥ã€‚è¿æ¥çš„æ–¹å¼ä¸`S2`å±‚ç±»ä¼¼ã€‚

### C5å·ç§¯å±‚(convolutional layer)

* è¾“å…¥ï¼š`S4`å±‚çš„å…¨éƒ¨16ä¸ªå•å…ƒ`featureMap`(ä¸`S4`å…¨ç›¸è¿)
* å·ç§¯æ ¸å¤§å°ï¼š$5\times5$
* å·ç§¯æ ¸ç§ç±»ï¼š120
* è¾“å‡º`featureMap`å¤§å°ï¼š$1\times1(5-5+1)$
* å¯è®­ç»ƒå‚æ•°/è¿æ¥ï¼š$120\times(16\times5\times5+1)=48120$

> `C5`å±‚æ˜¯ä¸€ä¸ªæœ‰120ä¸ª`featureMap`çš„å·ç§¯å±‚ã€‚æ¯ä¸€ä¸ªå•å…ƒå’Œ`S4`çš„æ‰€æœ‰16ä¸ª`featureMap`çš„ $5\times 5$â€‹ é‚»åŸŸå…¨è¿æ¥ã€‚å› ä¸º`S4`çš„`featureMap`æ˜¯ $5 \times 5$ ï¼Œæ‰€ä»¥`C5`çš„`featureMap`æ˜¯ $1\times1$ ã€‚

### F6å…¨è¿æ¥å±‚(fully-ocnnected layer)

* è¾“å…¥ï¼š`C5` 120ç»´å‘é‡
* è®¡ç®—æ–¹å¼ï¼šè®¡ç®—è¾“å…¥å‘é‡å’Œæƒé‡å‘é‡ä¹‹é—´çš„ç‚¹ç§¯ï¼Œå†åŠ ä¸Šä¸€ä¸ªåç½®ï¼Œç»“æœé€šè¿‡`sigmoid`å‡½æ•°è¾“å‡ºã€‚
* å¯è®­ç»ƒå‚æ•°ï¼š$84\times(120+1)=10164$

åŒ…å«84ä¸ªèŠ‚ç‚¹ï¼Œå¯¹åº”äºä¸€ä¸ª $7\times12$ çš„æ¯”ç‰¹å›¾ï¼Œ$-1$ è¡¨ç¤ºç™½è‰²ï¼Œ $1$â€‹ è¡¨ç¤ºé»‘è‰²ï¼Œè¿™æ ·æ¯ä¸ªç¬¦å·çš„æ¯”ç‰¹å›¾çš„é»‘ç™½è‰²å°±å¯¹åº”äºä¸€ä¸ªç¼–ç ã€‚

![](https://www.madao33.com/media/LeNet-5ç½‘ç»œä»¿çœŸå®ç°/fig3.png)

### output layer

æœ€åï¼Œè¾“å‡ºå±‚ç”±æ¬§å‡ é‡Œå¾—å¾„å‘åŸºå‡½æ•°(Euclidean Radial Basis Function)ç»„æˆï¼Œä¹Ÿæ˜¯å…¨è¿æ¥å±‚ã€‚å…±æœ‰10ä¸ªèŠ‚ç‚¹ï¼Œåˆ†åˆ«è¡¨ç¤º0åˆ°9ï¼Œå¯¹äºæ¯ä¸ª`RBF`å•å…ƒ$y_i$çš„è¾“å‡ºï¼š
$$
y_i = \sum_j(x_j-w_{ij})^2
$$

### æ€»ç»“

ç°åœ¨çš„å¤§å¤šæ•°ç¥ç»ç½‘ç»œæ˜¯é€šè¿‡`softmax`å‡½æ•°è¾“å‡ºå¤šåˆ†ç±»ç»“æœï¼Œç›¸æ¯”äºç°ä»£ç‰ˆæœ¬ï¼Œè¿™é‡Œå¾—åˆ°çš„ç¥ç»ç½‘ç»œä¼šå°ä¸€äº›ï¼Œåªæœ‰çº¦6ä¸‡ä¸ªå‚æ•°ï¼Œç°åœ¨çš„ä¸€äº›ç¥ç»ç½‘ç»œç”šè‡³æœ‰ä¸€åƒä¸‡åˆ°ä¸€äº¿ä¸ªå‚æ•°ã€‚

ä»`LeNet-5`ç½‘ç»œä»å·¦å¾€å³çœ‹ï¼Œéšç€ç½‘ç»œè¶Šæ¥è¶Šæ·±ï¼Œå›¾åƒçš„é«˜åº¦å’Œå®½åº¦éƒ½åœ¨ç¼©å°ï¼Œä»æœ€åˆçš„ $32\times32$â€‹ ç¼©å°åˆ° $28\times28$â€‹ï¼Œå†åˆ° $14\times14$â€‹ã€$10\times10$â€‹ï¼Œæœ€ååªç”¨ $5\times5$â€‹ï¼Œä¸æ­¤åŒæ—¶ï¼Œéšç€ç½‘ç»œå±‚æ¬¡çš„åŠ æ·±ï¼Œé€šé“æ•°é‡ä¸€ç›´åœ¨å¢åŠ ï¼Œä»1å¢åŠ åˆ°6ä¸ªï¼Œå†åˆ°16ä¸ªã€‚

LeNet5ç½‘ç»œçš„ç‰¹åˆ«ä¹‹å¤„è¿˜åœ¨äºï¼Œå„ä¸ªç½‘ç»œä¹‹é—´æ˜¯æœ‰å…³è”çš„ï¼Œæ¯”å¦‚è¯´ï¼Œä½ æœ‰ä¸€ä¸ª$nH\times nW\times nC$â€‹â€‹ çš„ç½‘ç»œï¼Œæœ‰$nC$â€‹â€‹ä¸ªé€šé“ï¼Œä½¿ç”¨å°ºå¯¸ä¸º$ğ‘“ Ã— ğ‘“ Ã— ğ‘› ğ¶ $â€‹çš„è¿‡æ»¤å™¨ï¼Œæ¯ä¸ªè¿‡æ»¤å™¨çš„é€šé“æ•°å’Œå®ƒä¸Šä¸€å±‚çš„é€šé“æ•°ç›¸åŒã€‚è¿™æ˜¯ç”±äºåœ¨å½“æ—¶ï¼Œè®¡ç®—æœºçš„è¿è¡Œé€Ÿåº¦éå¸¸æ…¢ï¼Œä¸ºäº†å‡å°‘è®¡ç®—é‡å’Œå‚æ•°ï¼Œç»å…¸çš„ `LeNet-5 `ç½‘ç»œä½¿ç”¨äº†éå¸¸å¤æ‚çš„è®¡ç®—æ–¹å¼ï¼Œæ¯ä¸ªè¿‡æ»¤å™¨éƒ½é‡‡ç”¨å’Œè¾“å…¥æ¨¡å—ä¸€æ ·çš„é€šé“æ•°é‡ã€‚

## LeNet-5ä»£ç å®ç°

### ç½‘ç»œæ¶æ„å®šä¹‰


```python
from collections import OrderedDict
import torch.nn as nn
class C1(nn.Module):
    def __init__(self):
        super(C1, self).__init__()

        self.c1 = nn.Sequential(OrderedDict([
            ('c1', nn.Conv2d(1, 6, kernel_size=(5, 5))),
            ('relu1', nn.ReLU()),
            ('s1', nn.MaxPool2d(kernel_size=(2, 2), stride=2))
        ]))

    def forward(self, img):
        output = self.c1(img)
        return output


class C2(nn.Module):
    def __init__(self):
        super(C2, self).__init__()

        self.c2 = nn.Sequential(OrderedDict([
            ('c2', nn.Conv2d(6, 16, kernel_size=(5, 5))),
            ('relu2', nn.ReLU()),
            ('s2', nn.MaxPool2d(kernel_size=(2, 2), stride=2))
        ]))

    def forward(self, img):
        output = self.c2(img)
        return output


class C3(nn.Module):
    def __init__(self):
        super(C3, self).__init__()

        self.c3 = nn.Sequential(OrderedDict([
            ('c3', nn.Conv2d(16, 120, kernel_size=(5, 5))),
            ('relu3', nn.ReLU())
        ]))

    def forward(self, img):
        output = self.c3(img)
        return output


class F4(nn.Module):
    def __init__(self):
        super(F4, self).__init__()

        self.f4 = nn.Sequential(OrderedDict([
            ('f4', nn.Linear(120, 84)),
            ('relu4', nn.ReLU())
        ]))

    def forward(self, img):
        output = self.f4(img)
        return output


class F5(nn.Module):
    def __init__(self):
        super(F5, self).__init__()

        self.f5 = nn.Sequential(OrderedDict([
            ('f5', nn.Linear(84, 10)),
            ('sig5', nn.LogSoftmax(dim=-1))
        ]))

    def forward(self, img):
        output = self.f5(img)
        return output


class LeNet5(nn.Module):
    """
    Input - 1x32x32
    Output - 10
    """
    def __init__(self):
        super(LeNet5, self).__init__()

        self.c1 = C1()
        self.c2_1 = C2() 
        self.c2_2 = C2() 
        self.c3 = C3() 
        self.f4 = F4() 
        self.f5 = F5() 

    def forward(self, img):
        output = self.c1(img)

        x = self.c2_1(output)
        output = self.c2_2(output)

        output += x

        output = self.c3(output)
        output = output.view(img.size(0), -1)
        output = self.f4(output)
        output = self.f5(output)
        return output

```

### æ•°æ®å‡†å¤‡

ä½¿ç”¨çš„æ•°æ®æ˜¯MNISTçš„æ‰‹å†™å­—ç¬¦é›†ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡`torchvision.datasets.mnist`è·å–


```python
from torchvision.datasets.mnist import MNIST
from lenet import LeNet5
import torch
import torch.optim as optim
from torchvision.datasets.mnist import MNIST
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import visdom
import onnx
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
```


è¿™é‡Œä½¿ç”¨äº†visdomæŸ¥çœ‹è®­ç»ƒæŸå¤±è¯¯å·®ï¼Œåœ¨è¿è¡Œè¿™æ®µä»£ç ä¹‹å‰åœ¨å‘½ä»¤è¡Œè¾“å…¥ï¼š
```bash
python3 -m visdom.server
```
ç„¶åæ‰“å¼€ç½‘å€ï¼š[http://localhost:8097/](http://localhost:8097/)ï¼Œå°±å¯ä»¥çœ‹åˆ°åŠ¨æ€çš„æŸå¤±è¯¯å·®

```python
viz = visdom.Visdom()
```

    Setting up a new session...



```python
data_train = MNIST('./data/mnist', 
                    download=True,
                    transform=transforms.transforms.Compose([
                        transforms.Resize((32, 32)), 
                        transforms.transforms.ToTensor()
                    ]))
data_test = MNIST('./data/mnist',
                    train=False,
                    download=True,
                    transform=transforms.transforms.Compose([
                        transforms.Resize((32, 32)),
                        transforms.ToTensor()])
                    )
```

    /home/madao/anaconda3/envs/python3.6env/lib/python3.6/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
      return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)



```python
data_train_loader = DataLoader(data_train, batch_size=256, shuffle=True, num_workers=8)
data_test_loader = DataLoader(data_test, batch_size=1024, num_workers=8)
```

### è®­ç»ƒåŠæµ‹è¯•


```python
net = LeNet5().to(device)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(net.parameters(), lr=2e-3)
cur_batch_win = None
cur_batch_win_opts = {
    'title': 'Epoch Loss Trace',
    'xlabel': 'Batch Number',
    'ylabel': 'Loss',
    'width': 1200,
    'height': 600,
}
```


```python
def train(epoch):
    global cur_batch_win
    global train_loss
    net.train()
    loss_list, batch_list = [], []
    for i, (images, labels) in enumerate(data_train_loader):
        optimizer.zero_grad()
        images = images.to(device)
        labels = labels.to(device)
        output = net(images)

        loss = criterion(output, labels)

        loss_list.append(loss.detach().cpu())
        batch_list.append(i+1)

        if i % 10 == 0:
            print('Train - Epoch %d, Batch: %d, Loss: %f' % (epoch, i, loss.detach().cpu().item()))

        # Update Visualization
        if viz.check_connection():
            cur_batch_win = viz.line(torch.Tensor(loss_list), torch.Tensor(batch_list),
                                     win=cur_batch_win, name='current_batch_loss'+str(epoch),
                                     update=(None if cur_batch_win is None else 'replace'),
                                     opts=cur_batch_win_opts)

        loss.backward()
        optimizer.step()
    return loss_list

```


```python
def test():
    net.eval()
    total_correct = 0
    avg_loss = 0.0

    for i, (images, labels) in enumerate(data_test_loader):
        images = images.to(device)
        labels = labels.to(device)
        output = net(images)

        avg_loss += criterion(output, labels).sum()
        pred = output.detach().cpu().max(1)[1]
        total_correct += pred.eq(labels.cpu().view_as(pred)).sum()

    avg_loss /= len(data_test)
    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss.detach().cpu().item(), float(total_correct) / len(data_test)))

```


```python
def train_and_test(epoch):
    train_loss = train(epoch)
    test()

    dummy_input = torch.randn(1, 1, 32, 32, requires_grad=True).to(device)
    torch.onnx.export(net, dummy_input, "lenet.onnx")

    onnx_model = onnx.load("lenet.onnx")
    onnx.checker.check_model(onnx_model)
    return train_loss
```


```python
def main():
    train_losss = list()
    for e in range(1, 16):
        train_loss = train_and_test(e)
        for loss in train_loss:
            train_losss.append(loss)
    return train_losss
```


```python
train_loss = main()
```

    /home/madao/anaconda3/envs/python3.6env/lib/python3.6/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
      return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)


    ....
    Train - Epoch 15, Batch: 220, Loss: 0.011107
    Train - Epoch 15, Batch: 230, Loss: 0.005971
    Test Avg. Loss: 0.000034, Accuracy: 0.990200

### æŸ¥çœ‹ç»“æœ

è®­ç»ƒçš„æŸå¤±è¯¯å·®å¦‚ä¸‹å›¾æ‰€ç¤º:

![](https://www.madao33.com/media/LeNet-5ç½‘ç»œä»¿çœŸå®ç°/train_loss.png)

åŠ¨æ€çš„è¯¯å·®å›¾å¯ä»¥å‚è€ƒï¼š
![](https://camo.githubusercontent.com/ac00da8517c1e2739f8e8af1cc0bacad5298bc6505153554d913d59e408f444c/68747470733a2f2f692e696d6775722e636f6d2f683468374372462e676966)

## å‚è€ƒæ–‡çŒ®

1. Lecun Y ,  Bottou L . Gradient-based learning applied to document recognition[J]. Proceedings of the IEEE, 1998, 86(11):2278-2324.

2. LeNetè¯¦è§£[WB/OL].https://blog.csdn.net/qq_42570457/article/details/81460807?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522162676641316780271556770%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=162676641316780271556770&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-81460807.pc_search_result_control_group&utm_term=Lenet&spm=1018.2226.3001.4187

3. DeepLearning AI.Andrew.Ng

