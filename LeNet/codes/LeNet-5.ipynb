{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('python3.6env': conda)"
  },
  "interpreter": {
   "hash": "03c9982e4e5e5aafe188fcddaa066fbf54983174d73da9138b399c741ef8645a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## å®šä¹‰LeNet-5ç½‘ç»œ"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LeNet-5ç½‘ç»œä»¿çœŸå®ç°\n",
    "\n",
    "## LeNet-5ç½‘ç»œæ¶æ„ä»‹ç»\n",
    "\n",
    "`LeNet-5`ç½‘ç»œæ¶æ„å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œä¸åŒ…æ‹¬è¾“å…¥å±‚çš„è¯ï¼Œ`LeNet-5`ä¸€å…±æœ‰7å±‚ï¼Œæ‰€æœ‰çš„å±‚éƒ½æœ‰å¯ä»¥è®­ç»ƒçš„å‚æ•°(æƒé‡).\n",
    "![](../imgs/lenet5.png)\n",
    "è¾“å…¥çš„å›¾åƒæ˜¯  $32\\times32$ å°ºå¯¸çš„ç‚¹é˜µå›¾ï¼Œè¿™æ¯”ç”¨äºè®­ç»ƒçš„æ•°æ®åº“ä¸­çš„æœ€å¤§çš„å­—ç¬¦è¿˜è¦å¤§(æ•°æ®åº“ä¸­çš„å¤§å¤šæ•°æ•°æ®å°ºå¯¸åœ¨ $20\\times20$â€‹â€‹â€‹â€‹)ã€‚è¿™æ ·åšçš„åŸå› æ˜¯æœŸæœ›è¯†åˆ«åˆ°æ½œåœ¨çš„åŒºåˆ«ç‰¹å¾ï¼Œä¾‹å¦‚ç¬”åˆ’ç»ˆç‚¹æˆ–è½¬è§’å¯ä»¥å‡ºç°åœ¨æœ€é«˜æ°´å¹³ç‰¹å¾æ£€æµ‹å™¨çš„æ„Ÿå—é‡çš„ä¸­å¿ƒã€‚åœ¨ $32\\times32$â€‹çš„è¾“å…¥æ•°æ®ä¸­ï¼ŒLeNet-5ç½‘ç»œçš„æœ€åä¸€å±‚å·ç§¯å±‚çš„æ„Ÿå—é‡ä¸­å¿ƒå½¢æˆ $20\\times20$â€‹çš„åŒºåŸŸã€‚\n",
    "\n",
    "è¾“å…¥çš„æ•°æ®ç»è¿‡å½’ä¸€åŒ–ï¼Œç™½è‰²çš„ç‚¹åœ¨-0.1ï¼Œé»‘è‰²çš„ç‚¹åœ¨1.175ï¼Œè¿™æ ·è®©è¾“å…¥çš„å¹³å‡å€¼åœ¨0å·¦å³ï¼Œæ–¹å·®åœ¨1å·¦å³ï¼Œå¯ä»¥åŠ é€Ÿå­¦ä¹ ã€‚\n",
    "\n",
    "\n",
    "è¿™ä¸ªç½‘ç»œæ¶æ„è™½ç„¶æ¯”è¾ƒå°ï¼Œä½†æ˜¯ä¹ŸåŒ…å«äº†æ·±åº¦å­¦ä¹ çš„ä¸»è¦çš„åŸºæœ¬æ¨¡å—ï¼š\n",
    "\n",
    "### input layer\n",
    "\n",
    "æ•°æ®è¾“å…¥å±‚ï¼Œå°†è¾“å…¥å›¾åƒå°ºå¯¸ç»Ÿä¸€å¹¶å½’ä¸€åŒ–ä¸º $32\\times32$\n",
    "\n",
    "### c1å·ç§¯å±‚(convolutional layer)\n",
    "\n",
    "* è¾“å…¥ï¼š$32 \\times 32$\n",
    "\n",
    "* å·ç§¯æ ¸å¤§å°ï¼š$5\\times5, s=1$â€‹\n",
    "\n",
    "* å·ç§¯ç§ç±»ï¼š6\n",
    "\n",
    "* ç¥ç»å…ƒæ•°é‡ï¼š$28\\times28\\times6$\n",
    "\n",
    "* å¯è®­ç»ƒå‚æ•°ï¼š$(5\\times5+1)\\times6=156$â€‹ \n",
    "\n",
    "  > æ¯ä¸ªæ»¤æ³¢å™¨ $5\\times5=25$â€‹ä¸ª`unit`å‚æ•°å’Œä¸€ä¸ª`bias`å‚æ•°ï¼Œä¸€å…±6ä¸ªæ»¤æ³¢å™¨\n",
    "\n",
    "* è¿æ¥æ•°ï¼š$(5\\times5+1)\\times6\\times28\\times28=122304$â€‹\n",
    "\n",
    "  > å·ç§¯å±‚`C1`å†…çš„æ¯ä¸ªåƒç´ éƒ½ä¸è¾“å…¥å›¾åƒä¸­çš„ $5\\times5$â€‹ä¸ªåƒç´ å’Œ1ä¸ªbiasæœ‰è¿æ¥ï¼Œæ‰€ä»¥æ€»å…±æœ‰ $156\\times28\\times28=12304$â€‹ ä¸ªè¿æ¥ç‚¹\n",
    "\n",
    "> å¯¹è¾“å…¥å›¾åƒè¿›è¡Œç¬¬ä¸€æ¬¡å·ç§¯è¿ç®—ï¼ˆä½¿ç”¨ 6 ä¸ªå¤§å°ä¸º $5\\times5$â€‹â€‹â€‹â€‹ çš„å·ç§¯æ ¸ï¼‰ï¼Œå¾—åˆ°6ä¸ª`C1`ç‰¹å¾å›¾ï¼ˆ6ä¸ªå¤§å°ä¸º$28\\times28$â€‹â€‹çš„ `feature maps`, 32-5+1=28ï¼‰ã€‚æˆ‘ä»¬å†æ¥çœ‹çœ‹éœ€è¦å¤šå°‘ä¸ªå‚æ•°ï¼Œå·ç§¯æ ¸çš„å¤§å°ä¸º$5\\times5$â€‹â€‹ï¼Œæ€»å…±å°±æœ‰$6\\times(5\\times5+1)=156$â€‹â€‹â€‹ä¸ªå‚æ•°ï¼Œå…¶ä¸­+1æ˜¯è¡¨ç¤ºä¸€ä¸ªæ ¸æœ‰ä¸€ä¸ª`bias`ã€‚å¯¹äºå·ç§¯å±‚`C1`ï¼Œ`C1`å†…çš„æ¯ä¸ªåƒç´ éƒ½ä¸è¾“å…¥å›¾åƒä¸­çš„$5\\times5$â€‹â€‹ä¸ªåƒç´ å’Œ1ä¸ª`bias`æœ‰è¿æ¥ï¼Œæ‰€ä»¥æ€»å…±æœ‰$156\\times28\\times28=122304$â€‹â€‹â€‹ä¸ªè¿æ¥ï¼ˆconnectionï¼‰ã€‚æœ‰122304ä¸ªè¿æ¥ï¼Œä½†æ˜¯æˆ‘ä»¬åªéœ€è¦å­¦ä¹ 156ä¸ªå‚æ•°ï¼Œä¸»è¦æ˜¯é€šè¿‡æƒå€¼å…±äº«å®ç°çš„ã€‚\n",
    "\n",
    "### S2æ± åŒ–å±‚(sub-sampS2ling layer)\n",
    "\n",
    "* è¾“å…¥ï¼š$28\\times28$\n",
    "* é‡‡æ ·åŒºåŸŸï¼š$2\\times2$\n",
    "* é‡‡æ ·æ–¹å¼ï¼š4ä¸ªè¾“å…¥ç›¸åŠ ï¼Œä¹˜ä»¥ä¸€ä¸ªå¯è®­ç»ƒå‚æ•°ï¼Œå†åŠ ä¸Šä¸€ä¸ªå¯è®­ç»ƒåç½®ã€‚ç»“æœé€šè¿‡`sigmoid`å‡½æ•°\n",
    "* é‡‡æ ·ç§ç±»ï¼š6\n",
    "* è¾“å‡º`featureMap`å¤§å°ï¼š$14\\times14(28/2)$â€‹\n",
    "* ç¥ç»å…ƒæ•°é‡ï¼š$14\\times14\\times6$â€‹\n",
    "* å¯è®­ç»ƒå‚æ•°ï¼š$2\\times6$â€‹(å’Œçš„æƒ+åç½®)\n",
    "* è¿æ¥æ•°ï¼š$(2\\times2+1)\\times6\\times14\\times14$â€‹\n",
    "* `S2`ä¸­æ¯ä¸ªç‰¹å¾å›¾çš„å¤§å°æ˜¯`C1`ä¸­ç‰¹å¾å›¾å¤§å°çš„1/4ã€‚\n",
    "\n",
    "> ç¬¬ä¸€æ¬¡å·ç§¯ä¹‹åç´§æ¥ç€å°±æ˜¯æ± åŒ–è¿ç®—ï¼Œä½¿ç”¨ $2\\times 2$â€‹â€‹â€‹æ ¸è¿›è¡Œæ± åŒ–ï¼Œäºæ˜¯å¾—åˆ°äº†`S2`ï¼Œ6ä¸ª$14\\times14$â€‹â€‹â€‹â€‹çš„ç‰¹å¾å›¾ï¼ˆ28/2=14ï¼‰ã€‚`S2`è¿™ä¸ªpoolingå±‚æ˜¯å¯¹C1ä¸­çš„ $2\\times2$â€‹â€‹â€‹â€‹ åŒºåŸŸå†…çš„åƒç´ æ±‚å’Œä¹˜ä»¥ä¸€ä¸ªæƒå€¼ç³»æ•°å†åŠ ä¸Šä¸€ä¸ªåç½®ï¼Œç„¶åå°†è¿™ä¸ªç»“æœå†åšä¸€æ¬¡æ˜ å°„ã€‚äºæ˜¯æ¯ä¸ªæ± åŒ–æ ¸æœ‰ä¸¤ä¸ªè®­ç»ƒå‚æ•°ï¼Œæ‰€ä»¥å…±æœ‰2x6=12ä¸ªè®­ç»ƒå‚æ•°ï¼Œä½†æ˜¯æœ‰5x14x14x6=5880ä¸ªè¿æ¥ã€‚\n",
    "\n",
    "### C3å·ç§¯å±‚(convolutional layer)\n",
    "\n",
    "* `S2`ä¸­æ‰€æœ‰6ä¸ªæˆ–è€…å‡ ä¸ªç‰¹å¾`map`ç»„åˆ\n",
    "* å·ç§¯æ ¸å¤§å°ï¼š$5\\times5$\n",
    "* å·ç§¯æ ¸ç§ç±»ï¼š16\n",
    "* è¾“å‡º`featureMap`å¤§å°ï¼š$10\\times10(14-5+1)=10$\n",
    "\n",
    "![](../imgs/table1.png)\n",
    "\n",
    "`C3`ä¸­çš„æ¯ä¸ªç‰¹å¾`map`æ˜¯è¿æ¥åˆ°`S2`ä¸­çš„æ‰€æœ‰6ä¸ªæˆ–è€…å‡ ä¸ªç‰¹å¾`map`çš„ï¼Œè¡¨ç¤ºæœ¬å±‚çš„ç‰¹å¾`map`æ˜¯ä¸Šä¸€å±‚æå–åˆ°çš„ç‰¹å¾`map`çš„ä¸åŒç»„åˆã€‚å­˜åœ¨çš„ä¸€ä¸ªæ–¹å¼æ˜¯ï¼š`C3`çš„å‰6ä¸ªç‰¹å¾å›¾ä»¥`S2`ä¸­3ä¸ªç›¸é‚»çš„ç‰¹å¾å›¾å­é›†ä¸ºè¾“å…¥ã€‚æ¥ä¸‹æ¥6ä¸ªç‰¹å¾å›¾ä»¥`S2`ä¸­4ä¸ªç›¸é‚»ç‰¹å¾å›¾å­é›†ä¸ºè¾“å…¥ã€‚ç„¶åçš„3ä¸ªä»¥ä¸ç›¸é‚»çš„4ä¸ªç‰¹å¾å›¾å­é›†ä¸ºè¾“å…¥ã€‚æœ€åä¸€ä¸ªå°†`S2`ä¸­æ‰€æœ‰ç‰¹å¾å›¾ä¸ºè¾“å…¥ã€‚åˆ™ï¼šå¯è®­ç»ƒå‚æ•°ï¼š\n",
    "$$\n",
    "6\\times(3\\times5\\times5+1)+6\\times(4\\times5\\times5+1)+3\\times(4\\times5\\times5+1)+\\times(6\\times5\\times5+1)=1516\n",
    "$$\n",
    "è¿™ç§éå¯¹ç§°çš„è¿æ¥çš„ä½œç”¨æ˜¯ï¼š\n",
    "\n",
    "* éå®Œå…¨è¿æ¥çš„æ–¹æ¡ˆå¯ä»¥ä½¿è¿æ¥æ•°ä¿æŒåœ¨åˆç†çš„èŒƒå›´å†…\n",
    "* ä¸åŒçš„ç‰¹å¾å›¾å› ä¸ºæœ‰ä¸åŒçš„ç‰¹å¾å¯ä»¥æå–å¤šç§ç»„åˆ\n",
    "\n",
    "### S4æ± åŒ–å±‚(sub-sampling layer)\n",
    "\n",
    "* è¾“å…¥ï¼š$10\\times10$\n",
    "* é‡‡æ ·åŒºåŸŸï¼š$2\\times2$\n",
    "* é‡‡æ ·æ–¹å¼ï¼š4ä¸ªè¾“å…¥ç›¸åŠ ï¼Œä¹˜ä»¥ä¸€ä¸ªå¯è®­ç»ƒå‚æ•°ï¼Œå†åŠ ä¸Šä¸€ä¸ªå¯è®­ç»ƒåç½®ã€‚ç»“æœé€šè¿‡`sigmoid`\n",
    "* é‡‡æ ·ç§ç±»ï¼š16\n",
    "* è¾“å‡º`featureMap`å¤§å°ï¼š$5\\times5$\n",
    "* ç¥ç»å…ƒæ•°é‡ï¼š$5\\times5\\times16=400$\n",
    "* å¯è®­ç»ƒå‚æ•°ï¼š$2\\times16=32$\n",
    "* è¿æ¥æ•°ï¼š$16\\times(2\\times2+1)\\times5\\times5=2000$â€‹\n",
    "* `S4`ä¸­æ¯ä¸ªç‰¹å¾å›¾çš„å¤§å°æ˜¯`C3`ä¸­ç‰¹å¾å›¾å¤§å°çš„1/4\n",
    "\n",
    "> `S4`æ˜¯`pooling`å±‚ï¼Œçª—å£å¤§å°ä»ç„¶æ˜¯$2\\times2$â€‹â€‹â€‹ï¼Œå…±è®¡16ä¸ª`feature map`ï¼Œ`C3`å±‚çš„16ä¸ª$10\\times10$â€‹â€‹â€‹çš„å›¾åˆ†åˆ«è¿›è¡Œä»¥$2\\times2$â€‹â€‹â€‹ä¸ºå•ä½çš„æ± åŒ–å¾—åˆ°16ä¸ª $5\\times5$â€‹â€‹â€‹ çš„ç‰¹å¾å›¾ã€‚è¿™ä¸€å±‚æœ‰2x16å…±32ä¸ªè®­ç»ƒå‚æ•°ï¼Œ$5\\times5\\times5\\times16=2000$â€‹â€‹ ä¸ªè¿æ¥ã€‚è¿æ¥çš„æ–¹å¼ä¸`S2`å±‚ç±»ä¼¼ã€‚\n",
    "\n",
    "### C5å·ç§¯å±‚(convolutional layer)\n",
    "\n",
    "* è¾“å…¥ï¼š`S4`å±‚çš„å…¨éƒ¨16ä¸ªå•å…ƒ`featureMap`(ä¸`S4`å…¨ç›¸è¿)\n",
    "* å·ç§¯æ ¸å¤§å°ï¼š$5\\times5$\n",
    "* å·ç§¯æ ¸ç§ç±»ï¼š120\n",
    "* è¾“å‡º`featureMap`å¤§å°ï¼š$1\\times1(5-5+1)$\n",
    "* å¯è®­ç»ƒå‚æ•°/è¿æ¥ï¼š$120\\times(16\\times5\\times5+1)=48120$\n",
    "\n",
    "> `C5`å±‚æ˜¯ä¸€ä¸ªæœ‰120ä¸ª`featureMap`çš„å·ç§¯å±‚ã€‚æ¯ä¸€ä¸ªå•å…ƒå’Œ`S4`çš„æ‰€æœ‰16ä¸ª`featureMap`çš„ $5\\times 5$â€‹ é‚»åŸŸå…¨è¿æ¥ã€‚å› ä¸º`S4`çš„`featureMap`æ˜¯ $5 \\times 5$ ï¼Œæ‰€ä»¥`C5`çš„`featureMap`æ˜¯ $1\\times1$ ã€‚\n",
    "\n",
    "### F6å…¨è¿æ¥å±‚(fully-ocnnected layer)\n",
    "\n",
    "* è¾“å…¥ï¼š`C5` 120ç»´å‘é‡\n",
    "* è®¡ç®—æ–¹å¼ï¼šè®¡ç®—è¾“å…¥å‘é‡å’Œæƒé‡å‘é‡ä¹‹é—´çš„ç‚¹ç§¯ï¼Œå†åŠ ä¸Šä¸€ä¸ªåç½®ï¼Œç»“æœé€šè¿‡`sigmoid`å‡½æ•°è¾“å‡ºã€‚\n",
    "* å¯è®­ç»ƒå‚æ•°ï¼š$84\\times(120+1)=10164$\n",
    "\n",
    "åŒ…å«84ä¸ªèŠ‚ç‚¹ï¼Œå¯¹åº”äºä¸€ä¸ª $7\\times12$ çš„æ¯”ç‰¹å›¾ï¼Œ$-1$ è¡¨ç¤ºç™½è‰²ï¼Œ $1$â€‹ è¡¨ç¤ºé»‘è‰²ï¼Œè¿™æ ·æ¯ä¸ªç¬¦å·çš„æ¯”ç‰¹å›¾çš„é»‘ç™½è‰²å°±å¯¹åº”äºä¸€ä¸ªç¼–ç ã€‚\n",
    "\n",
    "![](../imgs/fig3.png)\n",
    "\n",
    "### output layer\n",
    "\n",
    "æœ€åï¼Œè¾“å‡ºå±‚ç”±æ¬§å‡ é‡Œå¾—å¾„å‘åŸºå‡½æ•°(Euclidean Radial Basis Function)ç»„æˆï¼Œä¹Ÿæ˜¯å…¨è¿æ¥å±‚ã€‚å…±æœ‰10ä¸ªèŠ‚ç‚¹ï¼Œåˆ†åˆ«è¡¨ç¤º0åˆ°9ï¼Œå¯¹äºæ¯ä¸ª`RBF`å•å…ƒ$y_i$çš„è¾“å‡ºï¼š\n",
    "$$\n",
    "y_i = \\sum_j(x_j-w_{ij})^2\n",
    "$$\n",
    "\n",
    "### æ€»ç»“\n",
    "\n",
    "ç°åœ¨çš„å¤§å¤šæ•°ç¥ç»ç½‘ç»œæ˜¯é€šè¿‡`softmax`å‡½æ•°è¾“å‡ºå¤šåˆ†ç±»ç»“æœï¼Œç›¸æ¯”äºç°ä»£ç‰ˆæœ¬ï¼Œè¿™é‡Œå¾—åˆ°çš„ç¥ç»ç½‘ç»œä¼šå°ä¸€äº›ï¼Œåªæœ‰çº¦6ä¸‡ä¸ªå‚æ•°ï¼Œç°åœ¨çš„ä¸€äº›ç¥ç»ç½‘ç»œç”šè‡³æœ‰ä¸€åƒä¸‡åˆ°ä¸€äº¿ä¸ªå‚æ•°ã€‚\n",
    "\n",
    "ä»`LeNet-5`ç½‘ç»œä»å·¦å¾€å³çœ‹ï¼Œéšç€ç½‘ç»œè¶Šæ¥è¶Šæ·±ï¼Œå›¾åƒçš„é«˜åº¦å’Œå®½åº¦éƒ½åœ¨ç¼©å°ï¼Œä»æœ€åˆçš„ $32\\times32$â€‹ ç¼©å°åˆ° $28\\times28$â€‹ï¼Œå†åˆ° $14\\times14$â€‹ã€$10\\times10$â€‹ï¼Œæœ€ååªç”¨ $5\\times5$â€‹ï¼Œä¸æ­¤åŒæ—¶ï¼Œéšç€ç½‘ç»œå±‚æ¬¡çš„åŠ æ·±ï¼Œé€šé“æ•°é‡ä¸€ç›´åœ¨å¢åŠ ï¼Œä»1å¢åŠ åˆ°6ä¸ªï¼Œå†åˆ°16ä¸ªã€‚\n",
    "\n",
    "LeNet5ç½‘ç»œçš„ç‰¹åˆ«ä¹‹å¤„è¿˜åœ¨äºï¼Œå„ä¸ªç½‘ç»œä¹‹é—´æ˜¯æœ‰å…³è”çš„ï¼Œæ¯”å¦‚è¯´ï¼Œä½ æœ‰ä¸€ä¸ª$nH\\times nW\\times nC$â€‹â€‹ çš„ç½‘ç»œï¼Œæœ‰$nC$â€‹â€‹ä¸ªé€šé“ï¼Œä½¿ç”¨å°ºå¯¸ä¸º$ğ‘“ Ã— ğ‘“ Ã— ğ‘› ğ¶ $â€‹çš„è¿‡æ»¤å™¨ï¼Œæ¯ä¸ªè¿‡æ»¤å™¨çš„é€šé“æ•°å’Œå®ƒä¸Šä¸€å±‚çš„é€šé“æ•°ç›¸åŒã€‚è¿™æ˜¯ç”±äºåœ¨å½“æ—¶ï¼Œè®¡ç®—æœºçš„è¿è¡Œé€Ÿåº¦éå¸¸æ…¢ï¼Œä¸ºäº†å‡å°‘è®¡ç®—é‡å’Œå‚æ•°ï¼Œç»å…¸çš„ `LeNet-5 `ç½‘ç»œä½¿ç”¨äº†éå¸¸å¤æ‚çš„è®¡ç®—æ–¹å¼ï¼Œæ¯ä¸ªè¿‡æ»¤å™¨éƒ½é‡‡ç”¨å’Œè¾“å…¥æ¨¡å—ä¸€æ ·çš„é€šé“æ•°é‡ã€‚"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LeNet-5ç½‘ç»œå®šä¹‰"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "class C1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C1, self).__init__()\n",
    "\n",
    "        self.c1 = nn.Sequential(OrderedDict([\n",
    "            ('c1', nn.Conv2d(1, 6, kernel_size=(5, 5))),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('s1', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.c1(img)\n",
    "        return output\n",
    "\n",
    "\n",
    "class C2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C2, self).__init__()\n",
    "\n",
    "        self.c2 = nn.Sequential(OrderedDict([\n",
    "            ('c2', nn.Conv2d(6, 16, kernel_size=(5, 5))),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('s2', nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.c2(img)\n",
    "        return output\n",
    "\n",
    "\n",
    "class C3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C3, self).__init__()\n",
    "\n",
    "        self.c3 = nn.Sequential(OrderedDict([\n",
    "            ('c3', nn.Conv2d(16, 120, kernel_size=(5, 5))),\n",
    "            ('relu3', nn.ReLU())\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.c3(img)\n",
    "        return output\n",
    "\n",
    "\n",
    "class F4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F4, self).__init__()\n",
    "\n",
    "        self.f4 = nn.Sequential(OrderedDict([\n",
    "            ('f4', nn.Linear(120, 84)),\n",
    "            ('relu4', nn.ReLU())\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.f4(img)\n",
    "        return output\n",
    "\n",
    "\n",
    "class F5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F5, self).__init__()\n",
    "\n",
    "        self.f5 = nn.Sequential(OrderedDict([\n",
    "            ('f5', nn.Linear(84, 10)),\n",
    "            ('sig5', nn.LogSoftmax(dim=-1))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.f5(img)\n",
    "        return output\n",
    "\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    \"\"\"\n",
    "    Input - 1x32x32\n",
    "    Output - 10\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.c1 = C1()\n",
    "        self.c2_1 = C2() \n",
    "        self.c2_2 = C2() \n",
    "        self.c3 = C3() \n",
    "        self.f4 = F4() \n",
    "        self.f5 = F5() \n",
    "\n",
    "    def forward(self, img):\n",
    "        output = self.c1(img)\n",
    "\n",
    "        x = self.c2_1(output)\n",
    "        output = self.c2_2(output)\n",
    "\n",
    "        output += x\n",
    "\n",
    "        output = self.c3(output)\n",
    "        output = output.view(img.size(0), -1)\n",
    "        output = self.f4(output)\n",
    "        output = self.f5(output)\n",
    "        return output\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## æ•°æ®å‡†å¤‡\n",
    "\n",
    "ä½¿ç”¨çš„æ•°æ®æ˜¯MNISTçš„æ‰‹å†™å­—ç¬¦é›†ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡`torchvision.datasets.mnist`è·å–"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "from torchvision.datasets.mnist import MNIST\n",
    "from lenet import LeNet5\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import visdom\n",
    "import onnx\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "viz = visdom.Visdom()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "data_train = MNIST('./data/mnist', \n",
    "                    download=True,\n",
    "                    transform=transforms.transforms.Compose([\n",
    "                        transforms.Resize((32, 32)), \n",
    "                        transforms.transforms.ToTensor()\n",
    "                    ]))\n",
    "data_test = MNIST('./data/mnist',\n",
    "                    train=False,\n",
    "                    download=True,\n",
    "                    transform=transforms.transforms.Compose([\n",
    "                        transforms.Resize((32, 32)),\n",
    "                        transforms.ToTensor()])\n",
    "                    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "data_train_loader = DataLoader(data_train, batch_size=256, shuffle=True, num_workers=8)\n",
    "data_test_loader = DataLoader(data_test, batch_size=1024, num_workers=8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "net = LeNet5().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=2e-3)\n",
    "cur_batch_win = None\n",
    "cur_batch_win_opts = {\n",
    "    'title': 'Epoch Loss Trace',\n",
    "    'xlabel': 'Batch Number',\n",
    "    'ylabel': 'Loss',\n",
    "    'width': 1200,\n",
    "    'height': 600,\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "def train(epoch):\n",
    "    global cur_batch_win\n",
    "    net.train()\n",
    "    loss_list, batch_list = [], []\n",
    "    for i, (images, labels) in enumerate(data_train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = net(images)\n",
    "\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        loss_list.append(loss.detach().cpu())\n",
    "        batch_list.append(i+1)\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print('Train - Epoch %d, Batch: %d, Loss: %f' % (epoch, i, loss.detach().cpu().item()))\n",
    "\n",
    "        # Update Visualization\n",
    "        if viz.check_connection():\n",
    "            cur_batch_win = viz.line(torch.Tensor(loss_list), torch.Tensor(batch_list),\n",
    "                                     win=cur_batch_win, name='current_batch_loss'+str(epoch),\n",
    "                                     update=(None if cur_batch_win is None else 'replace'),\n",
    "                                     opts=cur_batch_win_opts)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "def test():\n",
    "    net.eval()\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(data_test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = net(images)\n",
    "\n",
    "        avg_loss += criterion(output, labels).sum()\n",
    "        pred = output.detach().cpu().max(1)[1]\n",
    "        total_correct += pred.eq(labels.cpu().view_as(pred)).sum()\n",
    "\n",
    "    avg_loss /= len(data_test)\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss.detach().cpu().item(), float(total_correct) / len(data_test)))\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def train_and_test(epoch):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "    dummy_input = torch.randn(1, 1, 32, 32, requires_grad=True).to(device)\n",
    "    torch.onnx.export(net, dummy_input, \"lenet.onnx\")\n",
    "\n",
    "    onnx_model = onnx.load(\"lenet.onnx\")\n",
    "    onnx.checker.check_model(onnx_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def main():\n",
    "    for e in range(1, 16):\n",
    "        train_and_test(e)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train - Epoch 1, Batch: 0, Loss: 2.310019\n",
      "Train - Epoch 1, Batch: 10, Loss: 1.752108\n",
      "Train - Epoch 1, Batch: 20, Loss: 0.929540\n",
      "Train - Epoch 1, Batch: 30, Loss: 0.659155\n",
      "Train - Epoch 1, Batch: 40, Loss: 0.600451\n",
      "Train - Epoch 1, Batch: 50, Loss: 0.525040\n",
      "Train - Epoch 1, Batch: 60, Loss: 0.442140\n",
      "Train - Epoch 1, Batch: 70, Loss: 0.414708\n",
      "Train - Epoch 1, Batch: 80, Loss: 0.305595\n",
      "Train - Epoch 1, Batch: 90, Loss: 0.228443\n",
      "Train - Epoch 1, Batch: 100, Loss: 0.227592\n",
      "Train - Epoch 1, Batch: 110, Loss: 0.297097\n",
      "Train - Epoch 1, Batch: 120, Loss: 0.202451\n",
      "Train - Epoch 1, Batch: 130, Loss: 0.234074\n",
      "Train - Epoch 1, Batch: 140, Loss: 0.124735\n",
      "Train - Epoch 1, Batch: 150, Loss: 0.184467\n",
      "Train - Epoch 1, Batch: 160, Loss: 0.139945\n",
      "Train - Epoch 1, Batch: 170, Loss: 0.145408\n",
      "Train - Epoch 1, Batch: 180, Loss: 0.134222\n",
      "Train - Epoch 1, Batch: 190, Loss: 0.192816\n",
      "Train - Epoch 1, Batch: 200, Loss: 0.154474\n",
      "Train - Epoch 1, Batch: 210, Loss: 0.135778\n",
      "Train - Epoch 1, Batch: 220, Loss: 0.141124\n",
      "Train - Epoch 1, Batch: 230, Loss: 0.160964\n",
      "Test Avg. Loss: 0.000118, Accuracy: 0.964000\n",
      "Train - Epoch 2, Batch: 0, Loss: 0.187966\n",
      "Train - Epoch 2, Batch: 10, Loss: 0.189266\n",
      "Train - Epoch 2, Batch: 20, Loss: 0.094599\n",
      "Train - Epoch 2, Batch: 30, Loss: 0.092561\n",
      "Train - Epoch 2, Batch: 40, Loss: 0.100277\n",
      "Train - Epoch 2, Batch: 50, Loss: 0.166138\n",
      "Train - Epoch 2, Batch: 60, Loss: 0.133650\n",
      "Train - Epoch 2, Batch: 70, Loss: 0.092836\n",
      "Train - Epoch 2, Batch: 80, Loss: 0.082826\n",
      "Train - Epoch 2, Batch: 90, Loss: 0.067225\n",
      "Train - Epoch 2, Batch: 100, Loss: 0.063126\n",
      "Train - Epoch 2, Batch: 110, Loss: 0.084583\n",
      "Train - Epoch 2, Batch: 120, Loss: 0.086398\n",
      "Train - Epoch 2, Batch: 130, Loss: 0.144487\n",
      "Train - Epoch 2, Batch: 140, Loss: 0.183461\n",
      "Train - Epoch 2, Batch: 150, Loss: 0.089760\n",
      "Train - Epoch 2, Batch: 160, Loss: 0.080518\n",
      "Train - Epoch 2, Batch: 170, Loss: 0.132796\n",
      "Train - Epoch 2, Batch: 180, Loss: 0.122537\n",
      "Train - Epoch 2, Batch: 190, Loss: 0.081076\n",
      "Train - Epoch 2, Batch: 200, Loss: 0.086551\n",
      "Train - Epoch 2, Batch: 210, Loss: 0.098619\n",
      "Train - Epoch 2, Batch: 220, Loss: 0.106265\n",
      "Train - Epoch 2, Batch: 230, Loss: 0.067322\n",
      "Test Avg. Loss: 0.000065, Accuracy: 0.978500\n",
      "Train - Epoch 3, Batch: 0, Loss: 0.116501\n",
      "Train - Epoch 3, Batch: 10, Loss: 0.057194\n",
      "Train - Epoch 3, Batch: 20, Loss: 0.069856\n",
      "Train - Epoch 3, Batch: 30, Loss: 0.036910\n",
      "Train - Epoch 3, Batch: 40, Loss: 0.038521\n",
      "Train - Epoch 3, Batch: 50, Loss: 0.039087\n",
      "Train - Epoch 3, Batch: 60, Loss: 0.059389\n",
      "Train - Epoch 3, Batch: 70, Loss: 0.071782\n",
      "Train - Epoch 3, Batch: 80, Loss: 0.084211\n",
      "Train - Epoch 3, Batch: 90, Loss: 0.047995\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(train_loss)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_loss' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-c058896c7dba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loss' is not defined"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Connection to remote host was lost.\n",
      "Connection to remote host was lost.\n",
      "Connection to remote host was lost.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}