{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# AlexNet代码实现\r\n",
    "\r\n",
    "鉴于原论文中使用的数据集过于庞大，分类过多，目前手头的设备运行是在过于缓慢，折中考虑尝试使用MNIST的数据集实现AlexNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch, torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import torch.nn as nn\r\n",
    "from torch import optim\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "import copy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 超参数设置\r\n",
    "EPOCH = 10\r\n",
    "BATCH_SIZE = 64\r\n",
    "LR = 0.01"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "transform = transforms.ToTensor()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集\r\n",
    "\r\n",
    "通过torchvision下载数据集"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "trainset = torchvision.datasets.MNIST(root='../data', train=True, download=False, transform=transform)\r\n",
    "testset = torchvision.datasets.MNIST(root='../data', train=True, transform=transform)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Roaming\\Python\\Python36\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\r\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "plt.imshow(trainset[4][0][0], cmap='gray')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x26bfe61bac8>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x26bfe565828>"
      ],
      "image/png": "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"
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "trainset[0][0].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## AlexNet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "class AlexNet(nn.Module):\r\n",
    "    def __init__(self,width_mult=1):\r\n",
    "        super(AlexNet, self).__init__()\r\n",
    "        self.layer1 = nn.Sequential(\r\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1), # 32*28*28\r\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 32*14*14\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            )\r\n",
    "        self.layer2 = nn.Sequential(\r\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1), # 64*14*14\r\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), # 64*7*7\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            )\r\n",
    "        self.layer3 = nn.Sequential(\r\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # 128*7*7\r\n",
    "            )\r\n",
    "        self.layer4 = nn.Sequential(\r\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1), # 256*7*7\r\n",
    "            )\r\n",
    " \r\n",
    "        self.layer5 = nn.Sequential(\r\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1), # 256*7*7\r\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2), # 256*3*3\r\n",
    "            nn.ReLU(inplace=True),\r\n",
    "            )\r\n",
    "        self.fc1 = nn.Linear(256*3*3, 1024)\r\n",
    "        self.fc2 = nn.Linear(1024, 512)\r\n",
    "        self.fc3 = nn.Linear(512, 10)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "        x = self.layer1(x)\r\n",
    "        x = self.layer2(x)\r\n",
    "        x = self.layer3(x)\r\n",
    "        x = self.layer4(x)\r\n",
    "        x = self.layer5(x)\r\n",
    "        x = x.view(-1, 256*3*3)\r\n",
    "        x = self.fc1(x)\r\n",
    "        x = self.fc2(x)\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "EPOCH = 5\r\n",
    "BATCH_SIZE = 128\r\n",
    "LR = 0.01"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "def validate(model, data):\r\n",
    "    total = 0\r\n",
    "    correct = 0\r\n",
    "    for i, (images, labels) in enumerate(data):\r\n",
    "        images = images.cpu()\r\n",
    "        x = net(images)\r\n",
    "        value, pred = torch.max(x,1)\r\n",
    "        pred = pred.data.cpu()\r\n",
    "        total += x.size(0)\r\n",
    "        correct += torch.sum(pred == labels)\r\n",
    "    return correct*100./total"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "net = AlexNet().to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# alexnet训练\r\n",
    "def train():\r\n",
    "    # 定义损失函数为交叉熵损失，优化方法为SGD\r\n",
    "    criterion = nn.CrossEntropyLoss() \r\n",
    "    optimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9)\r\n",
    "    max_accuracy=0\r\n",
    "    accuracies=[]\r\n",
    "    for epoch in range(EPOCH):\r\n",
    "        for i, (images,labels) in enumerate(trainloader):\r\n",
    "            images = images.to(device)\r\n",
    "            labels = labels.to(device)\r\n",
    "            optimizer.zero_grad()\r\n",
    "            outputs = net(images)\r\n",
    "            loss = criterion(outputs, labels)\r\n",
    "            loss_item = loss.item()\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "\r\n",
    "        accuracy = float(validate(criterion, testloader))\r\n",
    "        accuracies.append(accuracy)\r\n",
    "        print(\"Epoch %d accuracy: %f loss: %f\" % (epoch, accuracy, loss_item))\r\n",
    "        if accuracy > max_accuracy:\r\n",
    "            best_model = copy.deepcopy(criterion)\r\n",
    "            max_accuracy = accuracy\r\n",
    "            print(\"Saving Best Model with Accuracy: \", accuracy)\r\n",
    "        print('Epoch:', epoch+1, \"Accuracy :\", accuracy, '%')\r\n",
    "    plt.plot(accuracies)\r\n",
    "    return best_model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "alexnet = train()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Administrator\\.conda\\envs\\python3.6env\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 0 accuracy: 97.563332 loss: 0.181040\n",
      "Saving Best Model with Accuracy:  97.5633316040039\n",
      "Epoch: 1 Accuracy : 97.5633316040039 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.2 64-bit ('python3.6env': conda)"
  },
  "interpreter": {
   "hash": "7835acacaeaf508b921ecd27357232a38d5f7dc52657613320ee88843bc3a5f4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}